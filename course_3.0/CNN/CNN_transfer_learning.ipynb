{"cells": [{"cell_type": "markdown", "id": "18bf9dba", "metadata": {}, "source": ["# Image Classification using Transfer Learning\n", "We will classify images of cats and dogs using transfer learning models such as Inception, ResNet and VGGNet. "]}, {"cell_type": "code", "execution_count": null, "id": "e055f8fc", "metadata": {}, "outputs": [], "source": ["import tensorflow as tf\n", "import tarfile\n", "import urllib\n", "import os\n", "import numpy as np\n", "\n", "from matplotlib import pyplot as plt\n", "%matplotlib inline\n", "\n", "from tensorflow.keras.applications.inception_v3 import InceptionV3\n", "from tensorflow.keras.applications.vgg16 import VGG16\n", "from tensorflow.keras.applications.resnet50 import ResNet50\n", "from tensorflow.keras.applications import imagenet_utils\n", "   "]}, {"cell_type": "markdown", "id": "a819ccda", "metadata": {}, "source": ["# Google Cloud Storage Boilerplate\n", "\n", "The following two cells have some boilerplate to mount the Google Cloud Storage bucket containing the data used for this notebook to your Google Colab file system. **Even you are not using Google Colab, please make sure you run these two cells.** \n", "\n", "To access the data from Google Colab, you need to:\n", "\n", "1. Run the first cell;\n", "2. Follow the link when prompted (you may be asked to log in with your Google account);\n", "3. Copy the Google SDK token back into the prompt and press Enter;\n", "4. Run the second cell and wait until the data folder appears.\n", "\n", "If everything works correctly, a new folder called sciml-workshop-data should appear in the file browser on the left. Depending on the network speed, this may take one or two minutes. Ignore the warning \"You do not appear to have access to project ...\". If you are running the notebook locally or you have already connected to the bucket, these cells will have no side effects."]}, {"cell_type": "code", "execution_count": null, "id": "65ecfcb8", "metadata": {}, "outputs": [], "source": ["# variables passed to bash; do not change\n", "project_id = 'sciml-workshop'\n", "bucket_name = 'sciml-workshop'\n", "colab_data_path = '/content/sciml-workshop-data/'\n", "\n", "try:\n", "    from google.colab import auth\n", "    auth.authenticate_user()\n", "    google_colab_env = 'true'\n", "    data_path = colab_data_path\n", "except:\n", "    google_colab_env = 'false'\n", "    ###################################################\n", "    ######## specify your local data path here ########\n", "    ###################################################\n", "    with open('../local_data_path.txt', 'r') as f: data_path = f.read().splitlines()[0]"]}, {"cell_type": "code", "execution_count": null, "id": "0d4a5c21", "metadata": {}, "outputs": [], "source": ["%%bash -s {google_colab_env} {colab_data_path} {project_id} {bucket_name}\n", "\n", "# running locally\n", "if ! $1; then\n", "    echo \"Running notebook locally.\"\n", "    exit\n", "fi\n", "\n", "# already mounted\n", "if [ -d $2 ]; then\n", "    echo \"Data already mounted.\"\n", "    exit\n", "fi\n", "\n", "# mount the bucket\n", "echo \"deb http://packages.cloud.google.com/apt gcsfuse-bionic main\" > /etc/apt/sources.list.d/gcsfuse.list\n", "curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -\n", "apt -qq update\n", "apt -qq install gcsfuse\n", "gcloud config set project $3\n", "mkdir $2\n", "gcsfuse --implicit-dirs --limit-bytes-per-sec -1 --limit-ops-per-sec -1 $4 $2"]}, {"cell_type": "markdown", "id": "fcc1d339", "metadata": {}, "source": ["# Add label to each image\n", "\n", "This is a data preprocessing step which ensures a proper label is added to each image name. "]}, {"cell_type": "code", "execution_count": null, "id": "7969921d", "metadata": {}, "outputs": [], "source": ["def image_annotations(file_path):\n", "    annotations = {}\n", "    \n", "    with open(file_path, 'r') as f:\n", "        rows = f.read().splitlines()\n", "\n", "    for i, row in enumerate(rows):\n", "        image_name, _, _, _ = row.split(' ')\n", "        image_name += '.jpg'\n", "        if image_name[0].lower() != image_name[0]:\n", "            class_name = 'cat'\n", "        else:\n", "            class_name = 'dog'\n", "        annotations[image_name] = class_name\n", "    \n", "    return annotations, i + 1\n", "\n", "\n", "class_to_index = {'cat': 0, 'dog': 1}\n", "index_to_class = {0: 'cat', 1: 'dog'}\n", "\n", "train_path = os.path.join(data_path, 'transfer-data/annotations/trainval.txt')\n", "test_path = os.path.join(data_path, 'transfer-data/annotations/test.txt')\n", "\n", "train_annot, count_train = image_annotations(train_path)\n", "test_annot, count_test = image_annotations(test_path)\n", "\n", "print('Training examples count:', count_train)\n", "print('Test examples count:', count_test)"]}, {"cell_type": "markdown", "id": "aa0cec4d", "metadata": {}, "source": ["# Select images randomly\n", "\n", "A function is defined which is used to randomly choose images of given batch size."]}, {"cell_type": "code", "execution_count": null, "id": "2be39eab", "metadata": {}, "outputs": [], "source": ["image_dir = os.path.join(data_path, 'transfer-data/images')\n", "\n", "def get_random_batch(annot,model_name, batch_size=4):\n", "    all_keys = list(annot.keys())\n", "    total_examples = len(all_keys)\n", "    indices = np.random.choice(range(total_examples), batch_size)\n", "    x = np.zeros((batch_size, 128, 128, 3))\n", "    y = np.zeros((batch_size, 1))\n", "    images = []\n", "    \n", "    for i, index in enumerate(indices):\n", "        image = tf.keras.preprocessing.image.load_img(os.path.join(image_dir, all_keys[index]),\n", "                                                     target_size=(128, 128))\n", "        images.append(image)\n", "        arr = tf.keras.preprocessing.image.img_to_array(image)\n", "        if model_name == 'inception':\n", "            arr = tf.keras.applications.inception_v3.preprocess_input(arr)\n", "        elif model_name == 'vgg16' or model_name == 'resnet':  \n", "            arr = imagenet_utils.preprocess_input(arr)\n", "        arr = np.expand_dims(arr, axis=0)\n", "        x[i] = arr\n", "        y[i] = class_to_index[annot[all_keys[index]]]\n", "    \n", "    return x, y, images"]}, {"cell_type": "markdown", "id": "c767a051", "metadata": {}, "source": ["# Load pre-trained model\n", "\n", "Here we load a pre-trained model from Keras. The model is specified using the variable model_name. "]}, {"cell_type": "code", "execution_count": null, "id": "39a6c4d2", "metadata": {}, "outputs": [], "source": ["MODELS = {\n", "\"inception\": InceptionV3,\n", "\"resnet\": ResNet50,\n", "\"vgg16\": VGG16 }\n", "\n", "model_name = 'inception'\n", "Network = MODELS[model_name]\n", "\n", "base_model = Network(weights='imagenet', include_top=False,input_shape=(128, 128, 3), pooling='avg')\n", "base_model.summary()"]}, {"cell_type": "markdown", "id": "add6c1b1", "metadata": {}, "source": ["# Display images"]}, {"cell_type": "code", "execution_count": null, "id": "2c37ab5e", "metadata": {}, "outputs": [], "source": ["def display_images(x, y, p, images, index_to_class):\n", "    \n", "    if len(images) < 8:\n", "        print('Need at least 8 examples')\n", "        return None\n", "\n", "    plt.figure(figsize=(12, 8))\n", "    for i in range(8):\n", "        plt.subplot(2, 4, i + 1)\n", "        plt.imshow(images[i])\n", "        plt.xticks([])\n", "        plt.yticks([])\n", "        gt = int(np.squeeze(y[i]) > 0.5)\n", "        pred = int(np.squeeze(p[i]) > 0.5)\n", "        col = 'green' if gt == pred else 'red'\n", "        plt.xlabel(index_to_class[pred], color=col)\n", "    return plt\n", "\n", "x, y, images = get_random_batch(train_annot,model_name, batch_size=8)\n", "display_images(x, y, y, images, index_to_class).show()"]}, {"cell_type": "markdown", "id": "aca79d39", "metadata": {}, "source": ["# Build and compile model"]}, {"cell_type": "code", "execution_count": null, "id": "701cd113", "metadata": {}, "outputs": [], "source": ["def create_model():\n", "    model = tf.keras.models.Sequential([\n", "        base_model,\n", "        tf.keras.layers.Dropout(0.5),\n", "        tf.keras.layers.Dense(1, activation='sigmoid')\n", "    ])\n", "\n", "    model.layers[0].trainable = False\n", "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n", "    return model\n", "\n", "model = create_model()\n", "model.summary()"]}, {"cell_type": "code", "execution_count": null, "id": "dde33821", "metadata": {}, "outputs": [], "source": ["def data_generator(batch_size, annot):\n", "    while True:\n", "        x, y, _ = get_random_batch(annot,model_name, batch_size)\n", "        yield (x, y)"]}, {"cell_type": "code", "execution_count": null, "id": "4752461f", "metadata": {}, "outputs": [], "source": ["batch_size = 32\n", "steps_per_epoch = int(len(list(train_annot.keys()))/batch_size)\n", "validation_steps = int(len(list(test_annot.keys()))/batch_size)\n", "\n", "print('Steps per epoch:', steps_per_epoch)\n", "print('Validation steps:', validation_steps)\n"]}, {"cell_type": "markdown", "id": "5c753df6", "metadata": {}, "source": ["# Train model"]}, {"cell_type": "code", "execution_count": null, "id": "12d0b3d6", "metadata": {}, "outputs": [], "source": ["%%time\n", "\n", "H = model.fit(\n", "    data_generator(batch_size, train_annot),\n", "    validation_data=data_generator(batch_size, test_annot),\n", "    steps_per_epoch=steps_per_epoch,\n", "    validation_steps=validation_steps,\n", "    epochs=1\n", ")"]}, {"cell_type": "markdown", "id": "854116d9", "metadata": {}, "source": ["# Make predictions"]}, {"cell_type": "code", "execution_count": null, "id": "c47e5a49", "metadata": {}, "outputs": [], "source": ["x, y, images = get_random_batch(test_annot,model_name, batch_size=8)\n", "preds = model.predict(x)\n", "display_images(x, y, preds, images, index_to_class).show()"]}, {"cell_type": "code", "execution_count": null, "id": "a15ddb20", "metadata": {}, "outputs": [], "source": []}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.8.6"}}, "nbformat": 4, "nbformat_minor": 5}